{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ezzeldin-nasser939/Video-Vision-Transformer/blob/main/ViViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEm0yVnqwOfj",
        "outputId": "c1ea03c8-aef9-4e70-9a15-363275c197fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vit-pytorch in /usr/local/lib/python3.10/dist-packages (1.2.4)\n",
            "Requirement already satisfied: einops>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from vit-pytorch) (0.6.1)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from vit-pytorch) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from vit-pytorch) (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->vit-pytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->vit-pytorch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->vit-pytorch) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->vit-pytorch) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->vit-pytorch) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->vit-pytorch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->vit-pytorch) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->vit-pytorch) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->vit-pytorch) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->vit-pytorch) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->vit-pytorch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install vit-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import glob\n",
        "from itertools import chain\n",
        "import os\n",
        "import random\n",
        "import zipfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# from linformer import Linformer\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import keras\n",
        "#_____#\n",
        "import os, cv2\n",
        "#_____#\n",
        "import numpy as np\n",
        "#_____#\n",
        "import pandas as pd\n",
        "#_____#\n",
        "from PIL import Image\n",
        "#_____#\n",
        "import tensorflow as tf\n",
        "#_____#\n",
        "from pathlib import Path\n",
        "#_____#\n",
        "from keras import models\n",
        "#_____#\n",
        "from keras import layers\n",
        "#_____#\n",
        "import matplotlib.pyplot as plt\n",
        "#_____#\n",
        "from keras.utils import np_utils             # utilities for one-hot encoding of ground truth values\n",
        "#_____#\n",
        "from sklearn.utils import shuffle\n",
        "#_____#\n",
        "from keras.optimizers import Adam\n",
        "#_____#\n",
        "from skimage.util.dtype import convert\n",
        "#_____#\n",
        "from keras.models import *\n",
        "#_____#\n",
        "from sklearn.model_selection import train_test_split\n",
        "#_____#\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "#_____#\n",
        "from keras.layers import Conv2D, Reshape,  MaxPooling2D ,Input ,Dense , Dropout, Flatten  # convolution layers\n",
        "#_____#\n",
        "from keras.layers import BatchNormalization, GlobalAveragePooling2D, GlobalAveragePooling3D, ConvLSTM2D, Bidirectional,ConvLSTM1D ,Conv3D\n",
        "#_____#\n",
        "from sklearn.metrics import confusion_matrix ,accuracy_score,recall_score,f1_score,precision_score,classification_report"
      ],
      "metadata": {
        "id": "8dyaLAwpeykK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from vit_pytorch.vivit import ViT\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "SXgBW5eewd4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sNRvVh2wru_",
        "outputId": "cb9c54a4-76f1-4097-8bfd-2f007147795a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def sorted_alphanumeric(data):\n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n",
        "    return sorted(data, key=alphanum_key)"
      ],
      "metadata": {
        "id": "_JS6YxqaxEAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/videos'"
      ],
      "metadata": {
        "id": "VFtnIT2wxQhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = os.listdir(data_path)\n",
        "lst = sorted_alphanumeric(lst)\n",
        "# for vid_name in os.listdir(data_path):\n",
        "#   print(\"The video number :\",data_path+'/'+vid_name )"
      ],
      "metadata": {
        "id": "Sg19A4HExdym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aFhyiwCwwb8",
        "outputId": "652c006b-643f-47b7-c329-18dc3ad707bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1.mp4', '2.mp4', '3.mp4', '4.mp4', '5.mp4', '6.mp4', '7.mp4', '8.mp4', '9.mp4', '10.mp4', '11.mp4', '12.mp4', '13.mp4', '14.mp4', '15.mp4', '16.mp4', '17.mp4', '18.mp4', '19.mp4', '20.mp4', '21.mp4', '22.mp4', '23.mp4', '24.mp4', '25.mp4', '26.mp4', '27.mp4', '28.mp4', '29.mp4', '30.mp4', '31.mp4', '32.mp4', '33.mp4', '34.mp4', '35.mp4', '36.mp4', '37.mp4', '38.mp4', '39.mp4', '40.mp4', '41.mp4', '42.mp4', '43.mp4', '44.mp4', '45.mp4', '46.mp4', '47.mp4', '48.mp4', '49.mp4', '50.mp4', '51.mp4', '52.mp4', '53.mp4', '54.mp4', '55.mp4', '56.mp4', '57.mp4', '58.mp4', '59.mp4', '60.mp4', '61.mp4', '62.mp4', '63.mp4', '64.mp4', '65.mp4', '66.mp4', '67.mp4', '68.mp4', '69.mp4', '70.mp4', '71.mp4', '72.mp4', '73.mp4', '74.mp4', '75.mp4', '76.mp4', '77.mp4', '78.mp4', '79.mp4', '80.mp4', '81.mp4', '82.mp4', '83.mp4', '84.mp4', '85.mp4', '86.mp4', '87.mp4', '88.mp4', '89.mp4', '90.mp4', '91.mp4', '92.mp4', '93.mp4', '94.mp4', '95.mp4', '96.mp4', '97.mp4', '98.mp4', '99.mp4', '100.mp4', '101.mp4', '102.mp4', '103.mp4', '104.mp4', '105.mp4', '106.mp4', '107.mp4', '108.mp4', '109.mp4', '110.mp4', '111.mp4', '112.mp4', '113.mp4', '114.mp4', '115.mp4', '116.mp4', '117.mp4', '118.mp4', '119.mp4', '120.mp4', '121.mp4', '122.mp4', '123.mp4', '124.mp4', '125.mp4', '126.mp4', '127.mp4', '128.mp4', '129.mp4', '130.mp4', '131.mp4', '132.mp4', '133.mp4', '134.mp4', '135.mp4', '136.mp4', '137.mp4', '138.mp4', '139.mp4', '140.mp4', '141.mp4', '142.mp4', '143.mp4', '144.mp4', '145.mp4', '146.mp4', '147.mp4', '148.mp4', '149.mp4', '150.mp4', '151.mp4', '152.mp4', '153.mp4', '154.mp4', '155.mp4', '156.mp4', '157.mp4', '158.mp4', '159.mp4', '160.mp4', '161.mp4', '162.mp4', '163.mp4', '164.mp4', '165.mp4', '166.mp4', '167.mp4', '168.mp4', '169.mp4', '170.mp4', '171.mp4', '172.mp4', '173.mp4', '174.mp4', '175.mp4', '176.mp4', '177.mp4', '178.mp4', '179.mp4', '180.mp4', '181.mp4', '182.mp4', '183.mp4', '184.mp4', '185.mp4', '186.mp4', '187.mp4', '188.mp4', '189.mp4', '190.mp4', '191.mp4', '192.mp4', '193.mp4', '194.mp4', '195.mp4', '196.mp4', '197.mp4', '198.mp4', '199.mp4', '200.mp4', 'labeled_data_videos.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_frames(vid_name):\n",
        "    cap = cv2.VideoCapture(vid_name)\n",
        "    ret, frame = cap.read()\n",
        "    video_data = []\n",
        "    for i in range(100):\n",
        "        frame = cv2.resize(frame, (224,224), interpolation = cv2.INTER_AREA)\n",
        "        video_data.append(frame)\n",
        "    return video_data"
      ],
      "metadata": {
        "id": "jHVmswgdw2Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos=[]\n",
        "for vid_name in lst:\n",
        "    if vid_name == \"labeled_data_videos.csv\":\n",
        "      pass\n",
        "    else:\n",
        "      frames =np.array(get_video_frames(data_path+'/'+vid_name))\n",
        "      print(vid_name,\"Frames: \",frames.shape)\n",
        "      videos.append(frames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6p0ktf87fZn",
        "outputId": "df05b523-c443-477c-e3fa-b5c9c30018e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.mp4 Frames:  (100, 224, 224, 3)\n",
            "2.mp4 Frames:  (100, 224, 224, 3)\n",
            "3.mp4 Frames:  (100, 224, 224, 3)\n",
            "4.mp4 Frames:  (100, 224, 224, 3)\n",
            "5.mp4 Frames:  (100, 224, 224, 3)\n",
            "6.mp4 Frames:  (100, 224, 224, 3)\n",
            "7.mp4 Frames:  (100, 224, 224, 3)\n",
            "8.mp4 Frames:  (100, 224, 224, 3)\n",
            "9.mp4 Frames:  (100, 224, 224, 3)\n",
            "10.mp4 Frames:  (100, 224, 224, 3)\n",
            "11.mp4 Frames:  (100, 224, 224, 3)\n",
            "12.mp4 Frames:  (100, 224, 224, 3)\n",
            "13.mp4 Frames:  (100, 224, 224, 3)\n",
            "14.mp4 Frames:  (100, 224, 224, 3)\n",
            "15.mp4 Frames:  (100, 224, 224, 3)\n",
            "16.mp4 Frames:  (100, 224, 224, 3)\n",
            "17.mp4 Frames:  (100, 224, 224, 3)\n",
            "18.mp4 Frames:  (100, 224, 224, 3)\n",
            "19.mp4 Frames:  (100, 224, 224, 3)\n",
            "20.mp4 Frames:  (100, 224, 224, 3)\n",
            "21.mp4 Frames:  (100, 224, 224, 3)\n",
            "22.mp4 Frames:  (100, 224, 224, 3)\n",
            "23.mp4 Frames:  (100, 224, 224, 3)\n",
            "24.mp4 Frames:  (100, 224, 224, 3)\n",
            "25.mp4 Frames:  (100, 224, 224, 3)\n",
            "26.mp4 Frames:  (100, 224, 224, 3)\n",
            "27.mp4 Frames:  (100, 224, 224, 3)\n",
            "28.mp4 Frames:  (100, 224, 224, 3)\n",
            "29.mp4 Frames:  (100, 224, 224, 3)\n",
            "30.mp4 Frames:  (100, 224, 224, 3)\n",
            "31.mp4 Frames:  (100, 224, 224, 3)\n",
            "32.mp4 Frames:  (100, 224, 224, 3)\n",
            "33.mp4 Frames:  (100, 224, 224, 3)\n",
            "34.mp4 Frames:  (100, 224, 224, 3)\n",
            "35.mp4 Frames:  (100, 224, 224, 3)\n",
            "36.mp4 Frames:  (100, 224, 224, 3)\n",
            "37.mp4 Frames:  (100, 224, 224, 3)\n",
            "38.mp4 Frames:  (100, 224, 224, 3)\n",
            "39.mp4 Frames:  (100, 224, 224, 3)\n",
            "40.mp4 Frames:  (100, 224, 224, 3)\n",
            "41.mp4 Frames:  (100, 224, 224, 3)\n",
            "42.mp4 Frames:  (100, 224, 224, 3)\n",
            "43.mp4 Frames:  (100, 224, 224, 3)\n",
            "44.mp4 Frames:  (100, 224, 224, 3)\n",
            "45.mp4 Frames:  (100, 224, 224, 3)\n",
            "46.mp4 Frames:  (100, 224, 224, 3)\n",
            "47.mp4 Frames:  (100, 224, 224, 3)\n",
            "48.mp4 Frames:  (100, 224, 224, 3)\n",
            "49.mp4 Frames:  (100, 224, 224, 3)\n",
            "50.mp4 Frames:  (100, 224, 224, 3)\n",
            "51.mp4 Frames:  (100, 224, 224, 3)\n",
            "52.mp4 Frames:  (100, 224, 224, 3)\n",
            "53.mp4 Frames:  (100, 224, 224, 3)\n",
            "54.mp4 Frames:  (100, 224, 224, 3)\n",
            "55.mp4 Frames:  (100, 224, 224, 3)\n",
            "56.mp4 Frames:  (100, 224, 224, 3)\n",
            "57.mp4 Frames:  (100, 224, 224, 3)\n",
            "58.mp4 Frames:  (100, 224, 224, 3)\n",
            "59.mp4 Frames:  (100, 224, 224, 3)\n",
            "60.mp4 Frames:  (100, 224, 224, 3)\n",
            "61.mp4 Frames:  (100, 224, 224, 3)\n",
            "62.mp4 Frames:  (100, 224, 224, 3)\n",
            "63.mp4 Frames:  (100, 224, 224, 3)\n",
            "64.mp4 Frames:  (100, 224, 224, 3)\n",
            "65.mp4 Frames:  (100, 224, 224, 3)\n",
            "66.mp4 Frames:  (100, 224, 224, 3)\n",
            "67.mp4 Frames:  (100, 224, 224, 3)\n",
            "68.mp4 Frames:  (100, 224, 224, 3)\n",
            "69.mp4 Frames:  (100, 224, 224, 3)\n",
            "70.mp4 Frames:  (100, 224, 224, 3)\n",
            "71.mp4 Frames:  (100, 224, 224, 3)\n",
            "72.mp4 Frames:  (100, 224, 224, 3)\n",
            "73.mp4 Frames:  (100, 224, 224, 3)\n",
            "74.mp4 Frames:  (100, 224, 224, 3)\n",
            "75.mp4 Frames:  (100, 224, 224, 3)\n",
            "76.mp4 Frames:  (100, 224, 224, 3)\n",
            "77.mp4 Frames:  (100, 224, 224, 3)\n",
            "78.mp4 Frames:  (100, 224, 224, 3)\n",
            "79.mp4 Frames:  (100, 224, 224, 3)\n",
            "80.mp4 Frames:  (100, 224, 224, 3)\n",
            "81.mp4 Frames:  (100, 224, 224, 3)\n",
            "82.mp4 Frames:  (100, 224, 224, 3)\n",
            "83.mp4 Frames:  (100, 224, 224, 3)\n",
            "84.mp4 Frames:  (100, 224, 224, 3)\n",
            "85.mp4 Frames:  (100, 224, 224, 3)\n",
            "86.mp4 Frames:  (100, 224, 224, 3)\n",
            "87.mp4 Frames:  (100, 224, 224, 3)\n",
            "88.mp4 Frames:  (100, 224, 224, 3)\n",
            "89.mp4 Frames:  (100, 224, 224, 3)\n",
            "90.mp4 Frames:  (100, 224, 224, 3)\n",
            "91.mp4 Frames:  (100, 224, 224, 3)\n",
            "92.mp4 Frames:  (100, 224, 224, 3)\n",
            "93.mp4 Frames:  (100, 224, 224, 3)\n",
            "94.mp4 Frames:  (100, 224, 224, 3)\n",
            "95.mp4 Frames:  (100, 224, 224, 3)\n",
            "96.mp4 Frames:  (100, 224, 224, 3)\n",
            "97.mp4 Frames:  (100, 224, 224, 3)\n",
            "98.mp4 Frames:  (100, 224, 224, 3)\n",
            "99.mp4 Frames:  (100, 224, 224, 3)\n",
            "100.mp4 Frames:  (100, 224, 224, 3)\n",
            "101.mp4 Frames:  (100, 224, 224, 3)\n",
            "102.mp4 Frames:  (100, 224, 224, 3)\n",
            "103.mp4 Frames:  (100, 224, 224, 3)\n",
            "104.mp4 Frames:  (100, 224, 224, 3)\n",
            "105.mp4 Frames:  (100, 224, 224, 3)\n",
            "106.mp4 Frames:  (100, 224, 224, 3)\n",
            "107.mp4 Frames:  (100, 224, 224, 3)\n",
            "108.mp4 Frames:  (100, 224, 224, 3)\n",
            "109.mp4 Frames:  (100, 224, 224, 3)\n",
            "110.mp4 Frames:  (100, 224, 224, 3)\n",
            "111.mp4 Frames:  (100, 224, 224, 3)\n",
            "112.mp4 Frames:  (100, 224, 224, 3)\n",
            "113.mp4 Frames:  (100, 224, 224, 3)\n",
            "114.mp4 Frames:  (100, 224, 224, 3)\n",
            "115.mp4 Frames:  (100, 224, 224, 3)\n",
            "116.mp4 Frames:  (100, 224, 224, 3)\n",
            "117.mp4 Frames:  (100, 224, 224, 3)\n",
            "118.mp4 Frames:  (100, 224, 224, 3)\n",
            "119.mp4 Frames:  (100, 224, 224, 3)\n",
            "120.mp4 Frames:  (100, 224, 224, 3)\n",
            "121.mp4 Frames:  (100, 224, 224, 3)\n",
            "122.mp4 Frames:  (100, 224, 224, 3)\n",
            "123.mp4 Frames:  (100, 224, 224, 3)\n",
            "124.mp4 Frames:  (100, 224, 224, 3)\n",
            "125.mp4 Frames:  (100, 224, 224, 3)\n",
            "126.mp4 Frames:  (100, 224, 224, 3)\n",
            "127.mp4 Frames:  (100, 224, 224, 3)\n",
            "128.mp4 Frames:  (100, 224, 224, 3)\n",
            "129.mp4 Frames:  (100, 224, 224, 3)\n",
            "130.mp4 Frames:  (100, 224, 224, 3)\n",
            "131.mp4 Frames:  (100, 224, 224, 3)\n",
            "132.mp4 Frames:  (100, 224, 224, 3)\n",
            "133.mp4 Frames:  (100, 224, 224, 3)\n",
            "134.mp4 Frames:  (100, 224, 224, 3)\n",
            "135.mp4 Frames:  (100, 224, 224, 3)\n",
            "136.mp4 Frames:  (100, 224, 224, 3)\n",
            "137.mp4 Frames:  (100, 224, 224, 3)\n",
            "138.mp4 Frames:  (100, 224, 224, 3)\n",
            "139.mp4 Frames:  (100, 224, 224, 3)\n",
            "140.mp4 Frames:  (100, 224, 224, 3)\n",
            "141.mp4 Frames:  (100, 224, 224, 3)\n",
            "142.mp4 Frames:  (100, 224, 224, 3)\n",
            "143.mp4 Frames:  (100, 224, 224, 3)\n",
            "144.mp4 Frames:  (100, 224, 224, 3)\n",
            "145.mp4 Frames:  (100, 224, 224, 3)\n",
            "146.mp4 Frames:  (100, 224, 224, 3)\n",
            "147.mp4 Frames:  (100, 224, 224, 3)\n",
            "148.mp4 Frames:  (100, 224, 224, 3)\n",
            "149.mp4 Frames:  (100, 224, 224, 3)\n",
            "150.mp4 Frames:  (100, 224, 224, 3)\n",
            "151.mp4 Frames:  (100, 224, 224, 3)\n",
            "152.mp4 Frames:  (100, 224, 224, 3)\n",
            "153.mp4 Frames:  (100, 224, 224, 3)\n",
            "154.mp4 Frames:  (100, 224, 224, 3)\n",
            "155.mp4 Frames:  (100, 224, 224, 3)\n",
            "156.mp4 Frames:  (100, 224, 224, 3)\n",
            "157.mp4 Frames:  (100, 224, 224, 3)\n",
            "158.mp4 Frames:  (100, 224, 224, 3)\n",
            "159.mp4 Frames:  (100, 224, 224, 3)\n",
            "160.mp4 Frames:  (100, 224, 224, 3)\n",
            "161.mp4 Frames:  (100, 224, 224, 3)\n",
            "162.mp4 Frames:  (100, 224, 224, 3)\n",
            "163.mp4 Frames:  (100, 224, 224, 3)\n",
            "164.mp4 Frames:  (100, 224, 224, 3)\n",
            "165.mp4 Frames:  (100, 224, 224, 3)\n",
            "166.mp4 Frames:  (100, 224, 224, 3)\n",
            "167.mp4 Frames:  (100, 224, 224, 3)\n",
            "168.mp4 Frames:  (100, 224, 224, 3)\n",
            "169.mp4 Frames:  (100, 224, 224, 3)\n",
            "170.mp4 Frames:  (100, 224, 224, 3)\n",
            "171.mp4 Frames:  (100, 224, 224, 3)\n",
            "172.mp4 Frames:  (100, 224, 224, 3)\n",
            "173.mp4 Frames:  (100, 224, 224, 3)\n",
            "174.mp4 Frames:  (100, 224, 224, 3)\n",
            "175.mp4 Frames:  (100, 224, 224, 3)\n",
            "176.mp4 Frames:  (100, 224, 224, 3)\n",
            "177.mp4 Frames:  (100, 224, 224, 3)\n",
            "178.mp4 Frames:  (100, 224, 224, 3)\n",
            "179.mp4 Frames:  (100, 224, 224, 3)\n",
            "180.mp4 Frames:  (100, 224, 224, 3)\n",
            "181.mp4 Frames:  (100, 224, 224, 3)\n",
            "182.mp4 Frames:  (100, 224, 224, 3)\n",
            "183.mp4 Frames:  (100, 224, 224, 3)\n",
            "184.mp4 Frames:  (100, 224, 224, 3)\n",
            "185.mp4 Frames:  (100, 224, 224, 3)\n",
            "186.mp4 Frames:  (100, 224, 224, 3)\n",
            "187.mp4 Frames:  (100, 224, 224, 3)\n",
            "188.mp4 Frames:  (100, 224, 224, 3)\n",
            "189.mp4 Frames:  (100, 224, 224, 3)\n",
            "190.mp4 Frames:  (100, 224, 224, 3)\n",
            "191.mp4 Frames:  (100, 224, 224, 3)\n",
            "192.mp4 Frames:  (100, 224, 224, 3)\n",
            "193.mp4 Frames:  (100, 224, 224, 3)\n",
            "194.mp4 Frames:  (100, 224, 224, 3)\n",
            "195.mp4 Frames:  (100, 224, 224, 3)\n",
            "196.mp4 Frames:  (100, 224, 224, 3)\n",
            "197.mp4 Frames:  (100, 224, 224, 3)\n",
            "198.mp4 Frames:  (100, 224, 224, 3)\n",
            "199.mp4 Frames:  (100, 224, 224, 3)\n",
            "200.mp4 Frames:  (100, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/drive/MyDrive/videos/labeled_data_videos.csv')\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p6UM1mWbNNt",
        "outputId": "c93414d5-572a-4b13-c415-4e43073b8390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     videos  lable\n",
              "0         1      1\n",
              "1         2      1\n",
              "2         3      1\n",
              "3         4      1\n",
              "4         5      1\n",
              "..      ...    ...\n",
              "195     196      1\n",
              "196     197      1\n",
              "197     198      1\n",
              "198     199      1\n",
              "199     200      1\n",
              "\n",
              "[200 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-457b366a-99f2-446b-9aa6-ad1dbc2d30a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>videos</th>\n",
              "      <th>lable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>196</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>197</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>198</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>199</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>200</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-457b366a-99f2-446b-9aa6-ad1dbc2d30a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-457b366a-99f2-446b-9aa6-ad1dbc2d30a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-457b366a-99f2-446b-9aa6-ad1dbc2d30a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "lable=np.array(data['lable'].iloc[0:])"
      ],
      "metadata": {
        "id": "3PFw_H7Dt8no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lable.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRBjEhtruXbT",
        "outputId": "46463396-dc20-47df-ea0a-6f0740d897e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200,)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_data = np.transpose(videos, (0, 4, 1, 2, 3))\n",
        "reshaped_data.shape"
      ],
      "metadata": {
        "id": "G1k_baWsOLzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "temp = list(zip(reshaped_data, lable))\n",
        "random.shuffle(temp)\n",
        "reshaped_data, lable = zip(*temp)\n",
        "# reshaped_data, lable = np.array(reshaped_data),  np.array(lable)"
      ],
      "metadata": {
        "id": "ahvXUzQjW7Wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_data = reshaped_data[0:30]\n",
        "lable = lable[0:30]"
      ],
      "metadata": {
        "id": "ElfP5Dor_JDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training settings\n",
        "batch_size = 2\n",
        "epochs = 10\n",
        "lr = 3e-5\n",
        "gamma = 0.7\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "yLiil7sneSkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViT(\n",
        "    image_size = 224,          # image size\n",
        "    frames = 100,               # number of frames\n",
        "    image_patch_size = 32,     # image patch size\n",
        "    frame_patch_size = 20,      # frame patch size\n",
        "    num_classes = 1,\n",
        "    dim = 1024,\n",
        "    spatial_depth = 6,         # depth of the spatial transformer\n",
        "    temporal_depth = 6,        # depth of the temporal transformer\n",
        "    heads = 8,\n",
        "    mlp_dim = 2048\n",
        ")\n"
      ],
      "metadata": {
        "id": "6rso7-JpQ28S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "criterion = nn.BCELoss()\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "# scheduler\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
      ],
      "metadata": {
        "id": "R7TubnAWeMY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.labels[index]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "6ZmHPoaDd2U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lable=np.array(lable).reshape(-1,1)\n",
        "print(lable.shape)\n",
        "print(np.array(reshaped_data).shape)"
      ],
      "metadata": {
        "id": "qpT-SAtLGamT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_dataTensor = torch.from_numpy(np.array(reshaped_data)) # convert to tensors\n",
        "lableTensor = torch.from_numpy(np.array(lable))\n",
        "\n",
        "train_dataset = MyDataset(reshaped_dataTensor,lableTensor)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# train_loader = DataLoader(dataset = train, batch_size=batch_size, shuffle=True )"
      ],
      "metadata": {
        "id": "gmp4QltEd5Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\""
      ],
      "metadata": {
        "id": "cNYRK98z8ARA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "\n",
        "    for data, label in tqdm(train_loader):\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "        model = model.to(device)\n",
        "        output = model(data.float())\n",
        "        # print(output.detach().cpu().numpy().shape)\n",
        "        loss = criterion(output, label.float())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = (output.argmax(dim=1) == label).float().mean()\n",
        "        epoch_accuracy += acc / len(train_loader)\n",
        "        epoch_loss += loss / len(train_loader)\n",
        "        print(\n",
        "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f}\\n\"# - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
        "        )\n",
        "        torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "5lkGfWHLd_3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pT4BxeuCyPCF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}